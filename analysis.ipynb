{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_housing.csv')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Baseline Model\n",
    "In order to fit a baseline model for use in comparisons with the more complete model I will conduct these steps:\n",
    "1. Handle Muliticolinearity\n",
    "2. Standardize Variables\n",
    "3. Fit and Validate the Baseline Model\n",
    "\n",
    "## 1. Handle Multicolinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price              False\n",
       "bedrooms           False\n",
       "bathrooms          False\n",
       "sqft_living         True\n",
       "floors             False\n",
       "view               False\n",
       "grade              False\n",
       "sqft_above          True\n",
       "sqft_basement      False\n",
       "lat                False\n",
       "long               False\n",
       "sqft_living15      False\n",
       "WaterFront         False\n",
       "month_sold         False\n",
       "age                 True\n",
       "yrs_reno            True\n",
       "Renovated          False\n",
       "dist_to_Seattle    False\n",
       "Bellevue           False\n",
       "Federal Way        False\n",
       "Kent               False\n",
       "Renton             False\n",
       "Seattle            False\n",
       "rel_size           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_corr = ((abs(data.corr())> .8).sum()>1)\n",
    "high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_reno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sqft_living</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839924</td>\n",
       "      <td>-0.366368</td>\n",
       "      <td>-0.376163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sqft_above</td>\n",
       "      <td>0.839924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.483546</td>\n",
       "      <td>-0.482755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>age</td>\n",
       "      <td>-0.366368</td>\n",
       "      <td>-0.483546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>yrs_reno</td>\n",
       "      <td>-0.376163</td>\n",
       "      <td>-0.482755</td>\n",
       "      <td>0.938759</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sqft_living  sqft_above       age  yrs_reno\n",
       "sqft_living     1.000000    0.839924 -0.366368 -0.376163\n",
       "sqft_above      0.839924    1.000000 -0.483546 -0.482755\n",
       "age            -0.366368   -0.483546  1.000000  0.938759\n",
       "yrs_reno       -0.376163   -0.482755  0.938759  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['sqft_living', 'sqft_above', 'age', 'yrs_reno']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid multicolinearity issues I will drop sqft_above, because the information already exists in a combination of sqft_living and sqft_basement. I will also drop yrs_reno, because the data on whether the house has been renovated or not already exists in the renovated column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['sqft_above', 'yrs_reno'], axis = 1, \n",
    "          inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardize Variables \n",
    "To standardize the data I'll be using scikit learn's Robust Scalar function because of the existence of significant outliers in the independent variable, price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16262 entries, 0 to 16261\n",
      "Data columns (total 22 columns):\n",
      "price              16262 non-null float64\n",
      "bedrooms           16262 non-null int64\n",
      "bathrooms          16262 non-null float64\n",
      "sqft_living        16262 non-null int64\n",
      "floors             16262 non-null float64\n",
      "view               16262 non-null float64\n",
      "grade              16262 non-null int64\n",
      "sqft_basement      16262 non-null int64\n",
      "lat                16262 non-null float64\n",
      "long               16262 non-null float64\n",
      "sqft_living15      16262 non-null int64\n",
      "WaterFront         16262 non-null int64\n",
      "month_sold         16262 non-null int64\n",
      "age                16262 non-null int64\n",
      "Renovated          16262 non-null int64\n",
      "dist_to_Seattle    16262 non-null float64\n",
      "Bellevue           16262 non-null int64\n",
      "Federal Way        16262 non-null int64\n",
      "Kent               16262 non-null int64\n",
      "Renton             16262 non-null int64\n",
      "Seattle            16262 non-null int64\n",
      "rel_size           16262 non-null float64\n",
      "dtypes: float64(8), int64(14)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16262 entries, 0 to 16261\n",
      "Data columns (total 15 columns):\n",
      "price              16262 non-null float64\n",
      "bedrooms           16262 non-null int64\n",
      "bathrooms          16262 non-null float64\n",
      "sqft_living        16262 non-null int64\n",
      "floors             16262 non-null float64\n",
      "view               16262 non-null float64\n",
      "grade              16262 non-null int64\n",
      "sqft_basement      16262 non-null int64\n",
      "lat                16262 non-null float64\n",
      "long               16262 non-null float64\n",
      "sqft_living15      16262 non-null int64\n",
      "month_sold         16262 non-null int64\n",
      "age                16262 non-null int64\n",
      "dist_to_Seattle    16262 non-null float64\n",
      "rel_size           16262 non-null float64\n",
      "dtypes: float64(8), int64(7)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "#Separate data into categorical and continuous groups. \n",
    "cat_data = data[['WaterFront', 'Bellevue', 'Federal Way',\n",
    "                 'Kent', 'Renton', 'Seattle', 'Renovated']]\n",
    "\n",
    "con_data = data.drop(['WaterFront', 'Bellevue', \n",
    "                      'Federal Way', 'Kent', 'Renton', \n",
    "                      'Seattle', 'Renovated'], \n",
    "                     axis=1)\n",
    "con_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(col):\n",
    "    return(con_data[col]-\n",
    "           con_data[col].mean())/con_data[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = pd.DataFrame([])\n",
    "for col in con_data.columns:\n",
    "    scaled_data[col] = scale(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>floors</th>\n",
       "      <th>view</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>dist_to_Seattle</th>\n",
       "      <th>rel_size</th>\n",
       "      <th>WaterFront</th>\n",
       "      <th>Bellevue</th>\n",
       "      <th>Federal Way</th>\n",
       "      <th>Kent</th>\n",
       "      <th>Renton</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>1.626200e+04</td>\n",
       "      <td>16262.000000</td>\n",
       "      <td>16262.000000</td>\n",
       "      <td>16262.000000</td>\n",
       "      <td>16262.000000</td>\n",
       "      <td>16262.000000</td>\n",
       "      <td>16262.000000</td>\n",
       "      <td>16262.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.396415e-16</td>\n",
       "      <td>-1.339518e-15</td>\n",
       "      <td>1.764874e-15</td>\n",
       "      <td>2.311656e-16</td>\n",
       "      <td>5.501257e-14</td>\n",
       "      <td>-2.082494e-15</td>\n",
       "      <td>1.313944e-15</td>\n",
       "      <td>-4.521070e-15</td>\n",
       "      <td>-2.034863e-12</td>\n",
       "      <td>3.888316e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.037930e-15</td>\n",
       "      <td>-4.419537e-15</td>\n",
       "      <td>-1.550624e-14</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.253351</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.126491</td>\n",
       "      <td>0.159697</td>\n",
       "      <td>0.386176</td>\n",
       "      <td>0.027364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.434944</td>\n",
       "      <td>0.262240</td>\n",
       "      <td>0.332412</td>\n",
       "      <td>0.366336</td>\n",
       "      <td>0.486887</td>\n",
       "      <td>0.163148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.000057e+00</td>\n",
       "      <td>-2.761373e+00</td>\n",
       "      <td>-2.207734e+00</td>\n",
       "      <td>-2.194753e+00</td>\n",
       "      <td>-8.677580e-01</td>\n",
       "      <td>-2.329389e-01</td>\n",
       "      <td>-4.761209e+00</td>\n",
       "      <td>-6.559474e-01</td>\n",
       "      <td>-2.639059e+00</td>\n",
       "      <td>-1.915580e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.497173e+00</td>\n",
       "      <td>-1.631764e+00</td>\n",
       "      <td>-2.870654e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-7.874089e-01</td>\n",
       "      <td>-3.046371e-01</td>\n",
       "      <td>-7.224393e-01</td>\n",
       "      <td>-7.500213e-01</td>\n",
       "      <td>-8.677580e-01</td>\n",
       "      <td>-2.329389e-01</td>\n",
       "      <td>-4.435901e-01</td>\n",
       "      <td>-6.559474e-01</td>\n",
       "      <td>-6.177944e-01</td>\n",
       "      <td>-8.332727e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.359216e-01</td>\n",
       "      <td>-8.256997e-01</td>\n",
       "      <td>-5.527940e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.676110e-01</td>\n",
       "      <td>-3.046371e-01</td>\n",
       "      <td>2.020793e-02</td>\n",
       "      <td>-1.393616e-01</td>\n",
       "      <td>-8.677580e-01</td>\n",
       "      <td>-2.329389e-01</td>\n",
       "      <td>-4.435901e-01</td>\n",
       "      <td>-6.559474e-01</td>\n",
       "      <td>6.180182e-02</td>\n",
       "      <td>-3.080356e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.150707e-02</td>\n",
       "      <td>-1.701657e-01</td>\n",
       "      <td>-6.234055e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.374526e-01</td>\n",
       "      <td>9.237310e-01</td>\n",
       "      <td>7.628552e-01</td>\n",
       "      <td>6.202395e-01</td>\n",
       "      <td>9.616944e-01</td>\n",
       "      <td>-2.329389e-01</td>\n",
       "      <td>6.358147e-01</td>\n",
       "      <td>6.295063e-01</td>\n",
       "      <td>8.730094e-01</td>\n",
       "      <td>6.151085e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.818038e-01</td>\n",
       "      <td>6.634144e-01</td>\n",
       "      <td>3.991267e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.820085e+00</td>\n",
       "      <td>2.152099e+00</td>\n",
       "      <td>2.990797e+00</td>\n",
       "      <td>4.611869e+00</td>\n",
       "      <td>3.705873e+00</td>\n",
       "      <td>7.290503e+00</td>\n",
       "      <td>3.874029e+00</td>\n",
       "      <td>4.298405e+00</td>\n",
       "      <td>1.575423e+00</td>\n",
       "      <td>3.591452e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332544e+00</td>\n",
       "      <td>3.449029e+00</td>\n",
       "      <td>4.531018e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price      bedrooms     bathrooms   sqft_living        floors  \\\n",
       "count  1.626200e+04  1.626200e+04  1.626200e+04  1.626200e+04  1.626200e+04   \n",
       "mean   1.396415e-16 -1.339518e-15  1.764874e-15  2.311656e-16  5.501257e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.000057e+00 -2.761373e+00 -2.207734e+00 -2.194753e+00 -8.677580e-01   \n",
       "25%   -7.874089e-01 -3.046371e-01 -7.224393e-01 -7.500213e-01 -8.677580e-01   \n",
       "50%   -1.676110e-01 -3.046371e-01  2.020793e-02 -1.393616e-01 -8.677580e-01   \n",
       "75%    6.374526e-01  9.237310e-01  7.628552e-01  6.202395e-01  9.616944e-01   \n",
       "max    2.820085e+00  2.152099e+00  2.990797e+00  4.611869e+00  3.705873e+00   \n",
       "\n",
       "               view         grade  sqft_basement           lat          long  \\\n",
       "count  1.626200e+04  1.626200e+04   1.626200e+04  1.626200e+04  1.626200e+04   \n",
       "mean  -2.082494e-15  1.313944e-15  -4.521070e-15 -2.034863e-12  3.888316e-12   \n",
       "std    1.000000e+00  1.000000e+00   1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.329389e-01 -4.761209e+00  -6.559474e-01 -2.639059e+00 -1.915580e+00   \n",
       "25%   -2.329389e-01 -4.435901e-01  -6.559474e-01 -6.177944e-01 -8.332727e-01   \n",
       "50%   -2.329389e-01 -4.435901e-01  -6.559474e-01  6.180182e-02 -3.080356e-01   \n",
       "75%   -2.329389e-01  6.358147e-01   6.295063e-01  8.730094e-01  6.151085e-01   \n",
       "max    7.290503e+00  3.874029e+00   4.298405e+00  1.575423e+00  3.591452e+00   \n",
       "\n",
       "       ...           age  dist_to_Seattle      rel_size    WaterFront  \\\n",
       "count  ...  1.626200e+04     1.626200e+04  1.626200e+04  16262.000000   \n",
       "mean   ... -2.037930e-15    -4.419537e-15 -1.550624e-14      0.000615   \n",
       "std    ...  1.000000e+00     1.000000e+00  1.000000e+00      0.024791   \n",
       "min    ... -1.497173e+00    -1.631764e+00 -2.870654e+00      0.000000   \n",
       "25%    ... -9.359216e-01    -8.256997e-01 -5.527940e-01      0.000000   \n",
       "50%    ... -1.150707e-02    -1.701657e-01 -6.234055e-02      0.000000   \n",
       "75%    ...  6.818038e-01     6.634144e-01  3.991267e-01      0.000000   \n",
       "max    ...  2.332544e+00     3.449029e+00  4.531018e+00      1.000000   \n",
       "\n",
       "           Bellevue   Federal Way          Kent        Renton       Seattle  \\\n",
       "count  16262.000000  16262.000000  16262.000000  16262.000000  16262.000000   \n",
       "mean       0.253351      0.074284      0.126491      0.159697      0.386176   \n",
       "std        0.434944      0.262240      0.332412      0.366336      0.486887   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          Renovated  \n",
       "count  16262.000000  \n",
       "mean       0.027364  \n",
       "std        0.163148  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join continuous and categorical data. \n",
    "model_data = scaled_data.join(cat_data, how='outer')\n",
    "model_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop('price', axis=1)\n",
    "y = model_data['price']\n",
    "\n",
    "(X_train,X_test,\n",
    " y_train,y_test)=train_test_split(X,y,test_size=.2,\n",
    "                                  random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13009"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "model1 = linreg.fit(X_train,y_train)\n",
    "crossval = KFold(n_splits = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model, ind_train, ind_test, save_as = None):\n",
    "    \"\"\"\n",
    "    Print relevant statistics for a model.\n",
    "    \n",
    "    Parameters:\n",
    "    model: Fitted LinearRegression object\n",
    "    ind_train: independent variables for training set\n",
    "    ind_test: independent variables for test set\n",
    "    \"\"\"\n",
    "    pred_y_train = model.predict(ind_train)\n",
    "    pred_y_test = model.predict(ind_test)\n",
    "    \n",
    "    #Print top and bottome variables by size of coefficient.\n",
    "    coefs = []\n",
    "    high_coefs = []\n",
    "    low_coefs = []\n",
    "    for i in range(0, len(model.coef_)):\n",
    "        coefs.append((model.coef_[i],ind_train.columns[i]))\n",
    "    for coef in coefs:\n",
    "        if ((coef[0] \n",
    "            < np.quantile(model.coef_,.05))\n",
    "            or (coef[0] \n",
    "            > np.quantile(model.coef_,.95))):\n",
    "            high_coefs.append(coef)\n",
    "    for coef in coefs:\n",
    "        if ((coef[0] \n",
    "            < .05)\n",
    "            and (coef[0] \n",
    "            > -.05)):\n",
    "            low_coefs.append(coef)\n",
    "    print('************\\nHigh Impact Variables:\\n')\n",
    "    for variable in high_coefs:\n",
    "        print('Variable: {}\\nCoefficient: {}\\n'\n",
    "              .format(variable[1],variable[0]))\n",
    "    print('************')\n",
    "    print('************\\nLow Impact Variables:\\n')\n",
    "    for variable in low_coefs:\n",
    "        print('Variable: {}\\nCoefficient: {}\\n'\n",
    "              .format(variable[1],variable[0]))\n",
    "    print('************')\n",
    "\n",
    "    #Print MSE for the train an test set.\n",
    "    train_mse = mean_squared_error(y_train, pred_y_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_y_test)\n",
    "    print('\\nTrain MSE: {}\\nTest MSE: {}\\nDifference:{}\\n'\n",
    "          .format((train_mse),(test_mse),\n",
    "                  (train_mse-test_mse)))\n",
    "    \n",
    "    #Print R^2 against the test data. \n",
    "    print('Train R^2: {}'\n",
    "          .format((r2_score(y_train,pred_y_train))))\n",
    "    print('CrossValidated R^2: {}'\n",
    "          .format(np.mean(cross_val_score(model,\n",
    "                                          ind_train, y_train, \n",
    "                                          scoring ='r2', \n",
    "                                          cv = crossval))))\n",
    "    print('Test R^2: {}\\n'\n",
    "          .format(r2_score(y_test,pred_y_test)))\n",
    "    \n",
    "\n",
    "    plotdf = pd.DataFrame([])\n",
    "    plotdf['test_resids'] = pred_y_test-y_test\n",
    "    plotdf['y_test'] = y_test\n",
    "    \n",
    "    sns.jointplot(x = 'y_test', y = 'test_resids',\n",
    "                  data=plotdf, kind='kde')\n",
    "    plt.show()\n",
    "    if save_as != None:\n",
    "        plt.savefig(save_as);\n",
    "    \n",
    "    plt.scatter(pred_y_test, y_test)\n",
    "    plt.plot(y_test, y_test, color='black', \n",
    "             label='Actual Price')\n",
    "    plt.xlabel('Predicted Price')\n",
    "    plt.ylabel('Actual Price')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report(model1, X_train, X_test, \n",
    "       save_as = 'figures/Model1Resids.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the MSE and R-squared, the model seems fairly accurate, with a few problems. Namely it seems to lack predictive value for highly priced homes, and it predicts values into the negative values, which is of course impossible with housing prices. \n",
    "\n",
    "The variables floors, bedrooms, and month_sold appear to lack predictive influence. Information from the scatterplots during data exploration suggest that this is the result of the relationship being better modeled by polynomial regression.\n",
    "\n",
    "The low difference between MSE of the test set and MSE against the training set indicates that this model is not overfit.\n",
    "\n",
    "Finally, based on the KDE plot of residuals, it is clear that the model could be more generalizable, especially for high value homes. Interaction and polynomial features will likely improve predictive quality of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "In order to train the model and verify it's validity I will conduct the following steps:\n",
    "\n",
    "1. Find and include interaction features.\n",
    "2. Find and include polynomial features.\n",
    "3. Satisfy Assumptions.\n",
    "4. Validate Model\n",
    "\n",
    "## Find and Include Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interaction(col1, col2):\n",
    "    \"\"\"\n",
    "    Plot the regression lines of variables grouped by\n",
    "    high and low values. Non-parellel lines show \n",
    "    interaction of variables.\n",
    "    \n",
    "    Parameters:\n",
    "    col1: pandas Series. Variable to group by.\n",
    "    col2: pandas Series. Variable to plot by\n",
    "    \"\"\"\n",
    "    sample = X_train.join(y_train, how='outer')\n",
    "    \n",
    "    hisample = (sample.loc[sample[col1]\n",
    "                           >sample[col1].quantile(.66)])\n",
    "    midsample = (sample.loc[(sample[col1]\n",
    "                             >=sample[col1].quantile(.33))\n",
    "                            |(sample[col1]\n",
    "                              <=sample[col1].quantile(.66))])\n",
    "    losample = (sample.loc[sample[col1]\n",
    "                           <sample[col1].quantile(.33)])\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(6,3))\n",
    "    sns.regplot(x=col2, y='price', data=hisample, \n",
    "                scatter=False, truncate=True,\n",
    "                label='High Values of {}'.format(col1))\n",
    "    sns.regplot(x=col2, y='price', data=midsample, \n",
    "                scatter=False, truncate=True,\n",
    "                label='Middle Values of {}'.format(col1))\n",
    "    sns.regplot(x=col2, y='price', data=losample, \n",
    "                scatter=False, \n",
    "                label='Low Values of {}'.format(col1))\n",
    "    plt.title('Interaction of {} and {}'.format(col1, col2))\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    print('*********************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interactions(n, model, ind_train):\n",
    "    \"\"\"\n",
    "    Returns n most predictive interactions based on low MSE.\n",
    "    \n",
    "    Parameters:\n",
    "    n: int. the number of interactions selected.\n",
    "    model: LinearRegression() object being tested. \n",
    "    ind_train: the independent variables in the training set.\n",
    "    \"\"\"\n",
    "    combos = list(combinations(ind_train.columns, 2))\n",
    "    print('Testing {} combinations.\\n'.format(len(combos)))\n",
    "    inters = [(0,0,0)]*n\n",
    "    temp_X = ind_train.loc[:]\n",
    "    for combo in combos:\n",
    "        temp_X['interaction']=(ind_train.loc[:, combo[0]]\n",
    "                               *ind_train.loc[:, combo[1]])\n",
    "        linreg = LinearRegression()\n",
    "        model = linreg.fit(temp_X, y_train)\n",
    "        y_pred = model.predict(temp_X)\n",
    "        score = round(r2_score(y_train, y_pred),3)\n",
    "        if score > inters[-1][0]:\n",
    "            inters.append((score, combo[0], combo[1]))\n",
    "            inters = sorted(inters, reverse=True)[:n]\n",
    "    for inter in inters:\n",
    "        print('R^2 including interaction of {} and {}: {}'\n",
    "              .format(inter[1], inter[2], inter[0]))\n",
    "        plot_interaction(inter[1], inter[2])\n",
    "    fin_inters = [i[1:] for i in inters]\n",
    "    return fin_inters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interactions = find_interactions(15, model1, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Homes south of Seattle: {}'\n",
    "      .format(data[data['lat']<47.608013]['lat'].count()))\n",
    "print('Distance of Farthest Southern home: {}'\n",
    "      .format(47.608013-data['lat'].min()))\n",
    "print('Distance of Farthest Nothern home: {}'\n",
    "      .format(data['lat'].max()-47.608013))\n",
    "data['lat'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interactions:\n",
    "    var = pd.DataFrame(X_train[inter[0]] * X_train[inter[1]])\n",
    "    linreg = LinearRegression()\n",
    "    model = linreg.fit(var, y_train)\n",
    "    y_pred = model.predict(var)\n",
    "    plt.scatter(var, y_train, alpha=.2)\n",
    "    plt.scatter(var, y_pred, c='red')\n",
    "    plt.title('{}*{}'.format(inter[0], inter[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These interactions illustrate an interesting phenomenon. Despite the general trends, each city seems to have different reactions to the values of the other variables. This is most clear in the chart evaluating the impact of latitude on Bellevue: whereas in most cases the price of a home increases the farther North it is, in Bellevue the trend is reversed. \n",
    "\n",
    "Because of this, I will include the following interactions:\n",
    "- lat and dist_to_Seattle: houses in the middle latitudes drop in price more steeply than others as they gain distance from Seattle. This is likely the result of moving inland rather than north or south along the coast.\n",
    "\n",
    "- lat and Seattle: houses in the Northernmost set of data lose value if they are in Seattle compared to Southernmost set of data. This indicates that home values are likely higher in southern Seattle than they are in the northern part of the city.\n",
    "\n",
    "- sqft_living and dist_to_Seattle: Larger houses lose value at a steeper pace as they get farther from Seattle compared to middle sized homes which hold their value better.\n",
    "\n",
    "- long and Seattle: Houses farther to the West(the coastline) increase their value significantly more by being in Seattle than houses farther East.\n",
    "\n",
    "- lat and long: lat and long together tell a more complete piture of location.\n",
    "\n",
    "- lat and Bellevue: Houses at the Southern side of Bellevue are more expensive than houses at the Northern side.\n",
    "\n",
    "- sqft_living and Seattle: smaller houses increase in value more by being located in Seattle than larger houses.\n",
    "\n",
    "- long and dist_to_Seattle: middle values of longitude decrease in price at a slower rate as they get farther from Seattle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [('grade', 'dist_to_Seattle'),\n",
    "          ('sqft_living15', 'dist_to_Seattle'),\n",
    "          ('sqft_living', 'lat'), ('grade', 'lat'),\n",
    "          ('grade', 'Kent'), ('lat', 'Kent')]\n",
    "for inter in remove:\n",
    "    interactions.remove(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interactions(interactions, ind_train, ind_test):\n",
    "    \"\"\"\n",
    "    Use forward selection based on lowest MSE to select\n",
    "    and add most predictive interactions to a new model.\n",
    "    \n",
    "    Parameters:\n",
    "    interactions: list of tuples outputed by find_interaction\n",
    "    function.\n",
    "    ind_train: independent variables training data.\n",
    "    ind_test: independent variables test data.\n",
    "    \n",
    "    Returns:\n",
    "    (new_model, new_x_with_interactions)\n",
    "    \"\"\"\n",
    "    additions = interactions\n",
    "    X_temp_tr = ind_train.loc[:]\n",
    "    X_best_tr = ind_train.loc[:]\n",
    "    X_best_t = ind_test.loc[:]\n",
    "    scores = []\n",
    "    baseline = 0\n",
    "    while additions:\n",
    "        for inter in additions:\n",
    "            X_temp_tr[inter[0]\n",
    "                      +' * '\n",
    "                      +inter[1]]=(X_temp_tr.loc[:, inter[0]]\n",
    "                                  *X_temp_tr.loc[:, inter[1]])\n",
    "            linreg = LinearRegression()\n",
    "            model = linreg.fit(X_temp_tr, y_train)\n",
    "            y_pred = model.predict(X_temp_tr)\n",
    "            score = round(r2_score(y_train, y_pred),5)\n",
    "            scores.append((score, inter[0], inter[1]))\n",
    "            best = sorted(scores, reverse=True)[0]\n",
    "            x_temp_tr = X_best_tr.loc[:]\n",
    "        scores = []\n",
    "        if best[0] >= baseline:\n",
    "            additions.remove(best[1:])\n",
    "            baseline = best[0]\n",
    "            X_best_tr[best[1]\n",
    "                      +' * '\n",
    "                      +best[2]]=(X_temp_tr.loc[:, best[1]]\n",
    "                                 * X_temp_tr\n",
    "                                 .loc[:, best[2]])\n",
    "            X_best_t[best[1]\n",
    "                     +' * '\n",
    "                     +best[2]]=(X_best_t.loc[:, best[1]]\n",
    "                                *X_best_t.loc[:, best[2]])\n",
    "            linreg = LinearRegression()\n",
    "            model = linreg.fit(X_best_tr, y_train)\n",
    "            y_pred = model.predict(X_best_tr)\n",
    "            t_pred = model.predict(X_best_t)\n",
    "            print('Interaction Added: {} * {}'\n",
    "                  .format(best[1], best[2]))\n",
    "            print('Current R^2: {}'\n",
    "                  .format(best[0]))\n",
    "            print('Current Test MSE: {}'\n",
    "                  .format(round(mean_squared_error\n",
    "                                (y_test, t_pred),5)))\n",
    "            print('Current MSE Difference: {}\\n'\n",
    "                  .format(round(best[0]\n",
    "                          -round(mean_squared_error\n",
    "                                 (y_test, t_pred),5),5)))\n",
    "        else:\n",
    "            print('complete')\n",
    "            break\n",
    "    linreg = LinearRegression()\n",
    "    new_model = linreg.fit(X_best_tr, y_train)\n",
    "    return(new_model, X_best_tr, X_best_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2, X_train2, X_test2 = add_interactions(interactions, \n",
    "                                             X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(model2, X_train2, X_test2, \n",
    "       save_as = 'figures/Model2Resids.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and include Polynomial Features\n",
    "To find polynomial features I will iterate through the data, attempting to find data that suggests a polynomial relationship between price and the independent variable. I will then   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_features(ind_train, \n",
    "                            max_degree = 3):\n",
    "    features = []\n",
    "    for col in ind_train.columns:\n",
    "        scores = []\n",
    "        for degree in range(1,max_degree + 1):\n",
    "            df = pd.DataFrame(ind_train[col])\n",
    "            poly = PolynomialFeatures(degree)\n",
    "            X_poly_train = poly.fit_transform(df)\n",
    "            reg_poly = LinearRegression().fit(X_poly_train,\n",
    "                                              y_train)\n",
    "            y_pred = reg_poly.predict(X_poly_train)\n",
    "            score = round(mean_squared_error(y_train,\n",
    "                                             y_pred),5)\n",
    "            scores.append((score, degree, col, df, y_pred))\n",
    "            best_score = sorted(scores)[0] \n",
    "        if best_score[1] > 1:\n",
    "            print('Factor {} by {}'\n",
    "                  .format(best_score[2], \n",
    "                          best_score[1]))\n",
    "            plt.scatter(best_score[3], y_train, alpha = .1)\n",
    "            plt.scatter(best_score[3], best_score[4], \n",
    "                        c='red', label=('Predicted Values'))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            features.append((best_score[2], best_score[1]))\n",
    "    return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly_feat = get_polynomial_features(X_train2, \n",
    "                                    max_degree = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_polynomials(feats, ind_train, ind_test):\n",
    "    train = ind_train.loc[:]\n",
    "    test = ind_test.loc[:]\n",
    "    for feat in feats:\n",
    "        train_df = pd.DataFrame(ind_train[feat[0]])\n",
    "        test_df = pd.DataFrame(ind_test[feat[0]])\n",
    "        poly = PolynomialFeatures(feat[1])\n",
    "        poly_train = poly.fit_transform(train_df)\n",
    "        display(poly_train)\n",
    "        poly_test =poly.fit_transform(test_df)\n",
    "        train['{}^{}'.format(feat[0],feat[1])]=poly_train\n",
    "        test['{}^{}'.format(feat[0],feat[1])]=poly_test\n",
    "    return train, test\n",
    "\n",
    "#X_train3, X_test3 = add_polynomials(poly_feat, \n",
    " #                                   X_train2, X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the same function as PolynomialFeatures, but name\n",
    "# the columns.\n",
    "X_train3 = X_train2.loc[:]\n",
    "X_test3 = X_test2.loc[:]\n",
    "for feat in poly_feat:\n",
    "    factor = 2\n",
    "    while factor <= feat[1]:\n",
    "        poly_train = X_train2[feat[0]]**factor\n",
    "        poly_test = X_test2[feat[0]]**factor\n",
    "        X_train3['{}^{}'.format(feat[0], factor)]=poly_train\n",
    "        X_test3['{}^{}'.format(feat[0], factor)]=poly_test\n",
    "        factor +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "model3 = linreg.fit(X_train3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(model3, X_train3, X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_train3)\n",
    "len(y_train)\n",
    "#X_train3['resids']=y_train- y_pred\n",
    "#X_train3[X_train3['resids']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_variables(X,y):\n",
    "    \"\"\"\n",
    "    Forward selects variables by adjusted R^2.\n",
    "    \n",
    "    Parameters:\n",
    "    X: pandas dataframe. independent variables.\n",
    "    y: pandas series. dependent variable.\n",
    "    \n",
    "    Returns:\n",
    "    Optimized model. \n",
    "    \"\"\"\n",
    "current_score, best_score = 0, 0\n",
    "remaining = set(X.columns)\n",
    "selected = pd.DataFrame()\n",
    "while remaining and not current_score > best_score:\n",
    "    scores_with_candidates = []\n",
    "    for candidate in remaining:\n",
    "        test_x = selected.join(X[str(candidate)], how='outer')\n",
    "        score = sm.OLS(y,test_x).fit().rsquared_adj\n",
    "        scores_with_candidates.append((score,candidate))\n",
    "    scores_with_candidates.sort()\n",
    "    best_score, best_candidate = scores_with_candidates.pop()\n",
    "    if current_score < best_score:\n",
    "        remaining.remove(best_candidate)\n",
    "        selected = selected.join(X[str(best_candidate)], how='outer')\n",
    "        current_score = best_score\n",
    "print('Selected Columns: {}'.format(selected.columns))\n",
    "best_vars = sm.add_constant(selected)\n",
    "return best_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate(col):\n",
    "    ind_var = pd.DataFrame(X[col]) \n",
    "    frozen_var = X.drop(col, axis=1)\n",
    "    for fro_col in frozen_var.columns:\n",
    "        frozen_var[fro_col] = frozen_var[fro_col].mean()\n",
    "    iso_X = ind_var.join(frozen_var, how='outer')\n",
    "    return iso_X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
